---
title: "README"
output: html_document
---

# COMMIT SUMMARY
We have updated the code, thank you for your help Nico. We now need the USDZAR:CUR data (as suggested by you). We have also started with the stratification. We are struggling to understand it, but the code works. Please see questions in the relevant section.

We have made a start compiling the DCC and regression code from the tuts.


# Aim

The aim of this paper is to find the best hedge for a Rand depreciation

# Techniques used

We will most probably use DCC modelling
Maybe also eGARCH modelling, to compare the results to that of the DCC model


# NICO: Remember what I said in class - have a parametric (DCC) and also a non-parametric measure of a hedge (stratifying your data set)

# I'm happy for you to use the Dollar and e.g. Euro and Pound exchange rates - not always so sure about the currency's relative strength indices. Practitioners are mostly interested in ZARUSD.


# Data

## Data Prep

First we loaded the data ReturnsData and ETFs, respectively.

```{r Code for loading data}
library(tidyverse)

etfs <-
  readRDS("data/AllFunds.rds") %>% tbl_df()

data_original <-
  readRDS("data/SA_Rand_Returns.rds")
```


After this, we calculated the returns and merged data

```{r Calculating returns and merging datasets}

N_Capping <- 80 # Parameter that trims the universe set - won't be of much practical use if an obscure and small and thinly traded stock is a great hedge. Focus, e.g., on the top 80 stocks by Market Cap.

ETFReturns <-
etfs %>% group_by(Ticker) %>% 
  rename("TRI" = TOT_RETURN_INDEX_NET_DVDS) %>% 
  mutate(Return = TRI / lag(TRI)-1) %>% ungroup()

SAData_Returns <-   
data_original %>% 
  filter(Universe == "JALSHAll") %>% 
  mutate(Return = coalesce(Return, 0) ) %>%   # To make NA's zero - check whether this fits in to your study / makes sense --> motivate.
  ungroup() %>% select(date, Ticker, BICS_LEVEL_1_SECTOR_NAME, Market.Cap, Return) %>% 
  group_by(date) %>% 
  arrange(date, Market.Cap) %>% 
  top_n(N_Capping, "Market.Cap") %>% ungroup()

# And here's how to look at cumulative returns for e.g. Naspers:

SAData_Returns %>% filter(Ticker == "NPN SJ Equity") %>% mutate(cumret = cumprod(1+Return)*100) %>% ggplot() + geom_line(aes(date, cumret))


# Merging datasets:
mergeddataset <- 
bind_rows(
  ETFReturns %>% select(date, Ticker, Return),
  SAData_Returns %>% select(date, Ticker, Return)
  )# Assuming you don't want to look at sector levels..
  
# Is this what you are looking for? Yes, thank you

```

# Stratification

## Stratifying our data

QUESTION: The values created (under Df) - what are they based on/how are they genereated? We are just not sure where they come from, seeing as there is only dates in the function. 

```{r Stratification}
Df <-
  data.frame(
    date = dateconverter(ymd(20100101), ymd(20170901), Transform = "weekdayEOW"),
    Value = runif(length(dateconverter(ymd(20100101), ymd(20170901), Transform = "weekdayEOW")))
  )

StratValue1 <- 0.2 # Change threshold
StratValue2 <- 0.8 # Change threshold

df_Strat <- 
  Df %>% 
  mutate(Q1 = quantile(Value, StratValue1, na.rm = TRUE), Q2 = quantile(Value, StratValue2, na.rm = TRUE)) %>% 
  mutate(ID = ifelse(Value <= Q1, "Low", 
                     ifelse(Value > Q1 & Value <= Q2 , "Medium",
                            ifelse(Value > Q2 , "High", "NA")) )) %>% ungroup() 



HighDates <- df_Strat
LowDates <- df_Strat

# Now use these dates to truncate your sample in order to reflect your strata of choice.

# E.g., in your regression function:

# df %>% filter(date %in% HighDates) %>% ...  


```



# Miscellaneous Notes


***

# Paper

## Introduction

## Methodology

## Literature Review

## Results

## Conclusion


