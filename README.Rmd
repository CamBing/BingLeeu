---
title: "README"
output: html_document
---

# COMMIT SUMMARY
We have updated the code, thank you for your help Nico. We have tarted with the stratification. We are struggling to understand it, but the code works. Please see questions in the relevant section.

We have compiled the code for running multiple regressions. We have some questions (which follow the relevant section below)


# Aim

The aim of this paper is to find the best hedge for a Rand depreciation

# Techniques used

We will use a parametric (DCC) and a non-parametric measure of a hedge (stratifying the data set)

# NICO: Remember what I said in class - have a parametric (DCC) and also a non-parametric measure of a hedge (stratifying your data set)

# I'm happy for you to use the Dollar and e.g. Euro and Pound exchange rates - not always so sure about the currency's relative strength indices. Practitioners are mostly interested in ZARUSD.


# Data

## Data Prep

First we loaded the data ReturnsData and ETFs, respectively.

```{r Code for loading data}
library(tidyverse)

etfs <-
  readRDS("data/AllFunds.rds") %>% tbl_df()

data_original <-
  readRDS("data/SA_Rand_Returns.rds")

spots <-
  readRDS("data/Spots.rds")

```


After this, we calculated the returns and merged data
QUESTION: NICO: Please can you check how I calculated returns for usdzar.

```{r Calculating returns and merging datasets}

N_Capping <- 80 # Parameter that trims the universe set. Focus, e.g., on the top 80 stocks by Market Cap.

ETFReturns <-
etfs %>% group_by(Ticker) %>% 
  rename("TRI" = TOT_RETURN_INDEX_NET_DVDS) %>% 
  mutate(Return = TRI / lag(TRI)-1) %>% ungroup()

SAData_Returns <-   
data_original %>% 
  filter(Universe == "JALSHAll") %>% 
  mutate(Return = coalesce(Return, 0) ) %>%   # To make NA's zero - check whether this fits in to your study / makes sense --> motivate.
  ungroup() %>% select(date, Ticker, BICS_LEVEL_1_SECTOR_NAME, Market.Cap, Return) %>% 
  group_by(date) %>% 
  arrange(date, Market.Cap) %>% 
  top_n(N_Capping, "Market.Cap") %>% ungroup()

# Caluclating returns for USDZAR:

usdzar <- 
  spots %>% group_by(Spot) %>% 
  mutate(Return = Value/lag(Value)-1) %>%  
  filter(Spot == "ZAR_Spot") %>% 
  ungroup()

# And here's how to look at cumulative returns for e.g. Naspers:

SAData_Returns %>% filter(Ticker == "NPN SJ Equity") %>% mutate(cumret = cumprod(1+Return)*100) %>% ggplot() + geom_line(aes(date, cumret))


# Merging datasets:
mergeddataset <- 
  bind_rows(
    ETFReturns %>% select(date, Ticker, Return),
    SAData_Returns %>% select(date, Ticker, Return),
    usdzar %>% rename("Ticker" = Spot) %>% select(date, Ticker, Return)
  )

```

# Stratification

## Stratifying our data

QUESTION: The values created (under Df) - what are they based on/how are they genereated? We are just not sure where they come from, seeing as there is only dates in the function. 

```{r Stratification}
Df <-
  data.frame(
    date = dateconverter(ymd(20100101), ymd(20170901), Transform = "weekdayEOW"),
    Value = runif(length(dateconverter(ymd(20100101), ymd(20170901), Transform = "weekdayEOW")))
  )

StratValue1 <- 0.2 # Change threshold
StratValue2 <- 0.8 # Change threshold

df_Strat <- 
  Df %>% 
  mutate(Q1 = quantile(Value, StratValue1, na.rm = TRUE), Q2 = quantile(Value, StratValue2, na.rm = TRUE)) %>% 
  mutate(ID = ifelse(Value <= Q1, "Low", 
                     ifelse(Value > Q1 & Value <= Q2 , "Medium",
                            ifelse(Value > Q2 , "High", "NA")) )) %>% ungroup() 



HighDates <- df_Strat
LowDates <- df_Strat

# Now use these dates to truncate your sample in order to reflect your strata of choice.

# E.g., in your regression function:

# df %>% filter(date %in% HighDates) %>% ...  


```

# Regression Time

Code for this section follows in 'code/regressions.R'. Need to run 'code/data_prep.R' to get mergeddataset. Could we make this more efficient?

```{r Regressions}
# First off... -------------------------------------------------------------
#   Need to run 'code/data_prep.R' to obtain the mergeddataset

Regression_data <-   mergeddataset

# Packages ----------------------------------------------------------------
library(rmsfuns)
packages_reg <- c("broom")
load_pkg(packages_reg)

# REGRESSION ANALYSIS
# Running multiple regressions --------------------------------------------

zar_spot <- 
  Regression_data %>% 
  filter(Ticker == "ZAR_Spot")

Regressions <- 
  Regression_data %>%
  group_by(Ticker) %>% 
  do(reg = lm(Return ~ (Return), data = .)) ##*THIS IS WHAT MY QUESTION REFERS TO*## 

RegressionCoeffs <- 
  Regressions %>% tidy(reg)

head(RegressionCoeffs)


# Tidy output for the paper -----------------------------------------------

load_pkg("huxtable")

variable.names <- unique(Regression_data$Ticker, incomparables = FALSE) #**** WHAT SHOULD WE INCLUDE HERE? LEEU? - this includes ALL of our tickers  ****

Title <- "Regression Table"

 #*** This takes a while to run (1-2 mins)
ht <- 
  huxreg(Regressions %>% filter(Ticker %in% variable.names ) %>% 
           select(reg) %>% .[[1]], 
         statistics = c(N = "nobs", R2 = "r.squared"), 
         note = "%stars%." )

for(i in 1:ncol(ht)) {
  ht[1,][[1+i]] <- variable.names[i]  
}

ht %>% 
  set_caption(Title)
```
QUESTIONS:
\item What exactly should be regressed? (see comment in code above)
\item What are our variables of interest? All tickers? (see comment in code above)


# Miscellaneous Notes


***

# Paper

## Introduction

## Methodology

## Literature Review

## Results

## Conclusion


